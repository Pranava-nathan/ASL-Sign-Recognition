{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOacmEMbIEGK4KlO7Wm3BjC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install xarray netCDF4 h5netcdf cftime dask[complete] \\\n",
        "                 rioxarray rasterio leafmap folium \\\n",
        "                 numpy pandas tqdm imageio \\\n",
        "                 torch torchvision torchaudio \\\n",
        "                 pyngrok streamlit xskillscore"
      ],
      "metadata": {
        "id": "OPhmN4bRhe6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d147002-a37d-4e56-f241-24eb410b343d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.2/62.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m600.8/600.8 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m153.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.1/80.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m108.6/108.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.7/207.7 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install localtileserver matplotlib pillow"
      ],
      "metadata": {
        "id": "Ygexx0mbyD6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, numpy as np, pandas as pd, xarray as xr, dask, torch, platform, gc\n",
        "from pathlib import Path\n",
        "\n",
        "# Your uploaded files\n",
        "PATH_INST = \"/content/data_stream-oper_stepType-instant.nc\"\n",
        "PATH_ACC  = \"/content/data_stream-oper_stepType-accum.nc\"\n",
        "\n",
        "OUT_DIR = \"/content/neural_weather_outputs\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Keep memory stable while still training a strong model\n",
        "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
        "dask.config.set({\"array.slicing.split_large_chunks\": True})\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "CFG = {\n",
        "    \"tin\": 6,                   # past hours as input\n",
        "    \"lead_train\": 1,            # train for +1h\n",
        "    \"batch_size\": 2,            # keep small; we'll use grad accumulation\n",
        "    \"accum_steps\": 4,           # effective batch = batch_size * accum_steps\n",
        "    \"epochs\": 10,               # increase if you have time\n",
        "    \"lr\": 3e-4,\n",
        "    \"num_workers\": 0,           # single-process loader (most stable in Colab)\n",
        "    \"seed\": 42,\n",
        "    \"patch_hw\": 96,             # train on 96x96 patches (stronger than tiny patches)\n",
        "    \"samples_per_epoch\": 1500,  # many random samples per epoch\n",
        "    \"tile_patch\": 192,          # tile size at inference\n",
        "    \"tile_overlap\": 32,         # overlap to blend tiles\n",
        "}\n",
        "CFG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIY__mCNhhBy",
        "outputId": "acdc4028-6b49-433d-8f00-2790c5a4e3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tin': 6,\n",
              " 'lead_train': 1,\n",
              " 'batch_size': 2,\n",
              " 'accum_steps': 4,\n",
              " 'epochs': 10,\n",
              " 'lr': 0.0003,\n",
              " 'num_workers': 0,\n",
              " 'seed': 42,\n",
              " 'patch_hw': 96,\n",
              " 'samples_per_epoch': 1500,\n",
              " 'tile_patch': 192,\n",
              " 'tile_overlap': 32}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def open_nc_safe(path):\n",
        "    for eng in (\"netcdf4\", \"h5netcdf\", \"scipy\"):\n",
        "        try:\n",
        "            ds = xr.open_dataset(path, engine=eng, chunks={\"valid_time\": 24, \"time\": 24})\n",
        "            v0 = list(ds.data_vars)[0]\n",
        "            idx = {d: 0 for d in ds[v0].dims}\n",
        "            _ = ds[v0].isel(**idx).values\n",
        "            print(f\"Opened {path} with engine={eng}\")\n",
        "            return ds\n",
        "        except Exception as e:\n",
        "            print(f\"Engine {eng} failed for {path}: {e}\")\n",
        "    raise RuntimeError(f\"Failed to open {path} with any engine\")\n",
        "\n",
        "def harmonize_era5(ds):\n",
        "    if \"lon\" in ds.coords: ds = ds.rename({\"lon\": \"longitude\"})\n",
        "    if \"lat\" in ds.coords: ds = ds.rename({\"lat\": \"latitude\"})\n",
        "    if \"valid_time\" in ds.coords and \"time\" not in ds.coords:\n",
        "        ds = ds.rename({\"valid_time\": \"time\"})\n",
        "    if \"step\" in ds.dims:  # keep last step (hourly)\n",
        "        ds = ds.isel(step=-1).drop_vars(\"step\", errors=\"ignore\")\n",
        "    if \"expver\" in ds.dims:\n",
        "        ds = ds.isel(expver=0, drop=True)\n",
        "    return ds\n",
        "\n",
        "dsi = open_nc_safe(PATH_INST)\n",
        "dsa = open_nc_safe(PATH_ACC)\n",
        "dsi = harmonize_era5(dsi)\n",
        "dsa = harmonize_era5(dsa)\n",
        "\n",
        "# Rename short codes to long names if present\n",
        "rename_inst = {}\n",
        "if \"t2m\" in dsi: rename_inst[\"t2m\"] = \"2m_temperature\"\n",
        "if \"d2m\" in dsi: rename_inst[\"d2m\"] = \"2m_dewpoint_temperature\"\n",
        "if \"u10\" in dsi: rename_inst[\"u10\"] = \"10m_u_component_of_wind\"\n",
        "if \"v10\" in dsi: rename_inst[\"v10\"] = \"10m_v_component_of_wind\"\n",
        "if \"msl\" in dsi: rename_inst[\"msl\"] = \"mean_sea_level_pressure\"\n",
        "if \"tcc\" in dsi: rename_inst[\"tcc\"] = \"total_cloud_cover\"\n",
        "if \"tcwv\" in dsi: rename_inst[\"tcwv\"] = \"total_column_water_vapour\"\n",
        "if \"cape\" in dsi: rename_inst[\"cape\"] = \"convective_available_potential_energy\"\n",
        "dsi = dsi.rename(rename_inst)\n",
        "\n",
        "if \"tp\" in dsa:\n",
        "    dsa = dsa.rename({\"tp\": \"total_precipitation\"})\n",
        "\n",
        "print(\"INST vars:\", list(dsi.data_vars)[:10])\n",
        "print(\"ACC  vars:\", list(dsa.data_vars)[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq3j0WS_i6xL",
        "outputId": "d1f22f2e-812c-47bb-9e48-f536a3fab0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opened /content/data_stream-oper_stepType-instant.nc with engine=netcdf4\n",
            "Opened /content/data_stream-oper_stepType-accum.nc with engine=netcdf4\n",
            "INST vars: ['10m_u_component_of_wind', '10m_v_component_of_wind', '2m_temperature', 'mean_sea_level_pressure', 'total_cloud_cover', 'tcw', 'convective_available_potential_energy']\n",
            "ACC  vars: ['total_precipitation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictors (use all strong ones if present)\n",
        "keep_vars = [\n",
        "    \"2m_temperature\",\"2m_dewpoint_temperature\",\n",
        "    \"10m_u_component_of_wind\",\"10m_v_component_of_wind\",\n",
        "    \"mean_sea_level_pressure\",\"total_cloud_cover\",\n",
        "    \"total_column_water_vapour\",\"convective_available_potential_energy\"\n",
        "]\n",
        "inst = xr.Dataset({v: dsi[v] for v in keep_vars if v in dsi})\n",
        "\n",
        "# Unit conversions (lazy)\n",
        "if \"2m_temperature\" in inst: inst[\"2m_temperature\"] = inst[\"2m_temperature\"] - 273.15\n",
        "if \"2m_dewpoint_temperature\" in inst: inst[\"2m_dewpoint_temperature\"] = inst[\"2m_dewpoint_temperature\"] - 273.15\n",
        "if \"mean_sea_level_pressure\" in inst: inst[\"mean_sea_level_pressure\"] = inst[\"mean_sea_level_pressure\"] / 100.0\n",
        "\n",
        "# Precip: m -> mm/h (hourly accumulation)\n",
        "assert \"total_precipitation\" in dsa, \"total_precipitation not found in accum file\"\n",
        "tp_mmph = (dsa[\"total_precipitation\"] * 1000.0).rename(\"tp_mmph\")\n",
        "\n",
        "# Merge by common coords\n",
        "ds = xr.merge([inst, tp_mmph.to_dataset()], join=\"inner\")\n",
        "lat = ds[\"latitude\"].values\n",
        "lon = ds[\"longitude\"].values\n",
        "print(\"Grid:\", len(lat), \"x\", len(lon), \"| Time:\", ds.time.size)\n",
        "print(\"Merged vars:\", list(ds.data_vars))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkO-1JJKjANz",
        "outputId": "bdf89147-1ddf-47fa-9fa7-f1be0e25eb22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid: 125 x 121 | Time: 720\n",
            "Merged vars: ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'mean_sea_level_pressure', 'total_cloud_cover', 'convective_available_potential_energy', 'tp_mmph']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = ds.sel(time=slice(\"2025-04-01\", \"2025-04-20\"))\n",
        "val_ds   = ds.sel(time=slice(\"2025-04-21\", \"2025-04-26\"))\n",
        "test_ds  = ds.sel(time=slice(\"2025-04-27\", \"2025-04-30\"))\n",
        "print(train_ds.time.size, val_ds.time.size, test_ds.time.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9csW1uTjBoX",
        "outputId": "4dd44edf-991e-45cb-d6e3-90945805cd97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "480 144 96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_avail = [v for v in keep_vars if v in train_ds]\n",
        "# Sample every 6th hour for stats (good enough)\n",
        "Xsample = train_ds[preds_avail].isel(time=slice(0, None, 6)).to_array(\"channel\")\n",
        "mean = Xsample.mean(dim=(\"time\",\"latitude\",\"longitude\"))\n",
        "std  = Xsample.std(dim=(\"time\",\"latitude\",\"longitude\")) + 1e-6\n",
        "\n",
        "# Store as numpy aligned to the same order\n",
        "mean_np = mean.values.astype(np.float32)\n",
        "std_np  = std.values.astype(np.float32)\n",
        "print(\"Channels:\", list(mean.channel.values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvfq_x-8jFtb",
        "outputId": "aebbb397-7a52-4243-f398-edbd39449cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels: ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'mean_sea_level_pressure', 'total_cloud_cover', 'convective_available_potential_energy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Repair cell: define device and rebuild training objects\n",
        "import torch, gc\n",
        "from torch.optim import AdamW\n",
        "import torch.nn as nn\n",
        "\n",
        "# 1) Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# 2) Sanity: ensure these exist (rerun your normalization cell if not)\n",
        "assert 'preds_avail' in globals(), \"Run the normalization cell to define preds_avail\"\n",
        "assert 'mean_np' in globals() and 'std_np' in globals(), \"Run the normalization cell to define mean/std\"\n",
        "assert 'UNet3DNowcast' in globals(), \"Run the model class cell first\"\n",
        "assert 'CFG' in globals(), \"Run the config cell first\"\n",
        "\n",
        "# 3) (Re)build model + optimizer + loss + scaler\n",
        "in_ch = len(preds_avail) + 4  # 4 time-feature channels\n",
        "model = UNet3DNowcast(in_ch=in_ch, base=16).to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=CFG[\"lr\"])\n",
        "loss_fn = nn.SmoothL1Loss(beta=0.5)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n",
        "\n",
        "# 4) If you need DataLoaders again (after a restart), recreate them:\n",
        "if 'train_loader' not in globals() or 'val_loader' not in globals():\n",
        "    from torch.utils.data import DataLoader\n",
        "    pin = False  # keep False for Colab stability\n",
        "    train_loader = DataLoader(train_set, batch_size=CFG[\"batch_size\"], shuffle=True,\n",
        "                              num_workers=CFG[\"num_workers\"], pin_memory=pin, persistent_workers=False)\n",
        "    val_loader   = DataLoader(val_set,   batch_size=CFG[\"batch_size\"], shuffle=False,\n",
        "                              num_workers=CFG[\"num_workers\"], pin_memory=pin, persistent_workers=False)\n",
        "\n",
        "# 5) Optional: sanity check one batch (helps catch shape issues early)\n",
        "xb, yb = next(iter(train_loader))\n",
        "print(\"xb:\", tuple(xb.shape), \"yb:\", tuple(yb.shape))  # expect [B, C+4, Tin, H, W] and [B, 1, H, W]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZJcP39cn1wg",
        "outputId": "ab1e89a9-577b-4b89-b51f-9b0d03b1b3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "xb: (2, 10, 6, 96, 96) yb: (2, 1, 96, 96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def make_time_feats(times):\n",
        "    t = pd.to_datetime(times)\n",
        "    hod = t.hour + t.minute/60.0\n",
        "    hod_sin = np.sin(2*np.pi*hod/24.0)\n",
        "    hod_cos = np.cos(2*np.pi*hod/24.0)\n",
        "    doy = t.dayofyear\n",
        "    doy_sin = np.sin(2*np.pi*(doy-1)/365.0)\n",
        "    doy_cos = np.cos(2*np.pi*(doy-1)/365.0)\n",
        "    return np.stack([hod_sin, hod_cos, doy_sin, doy_cos], axis=1).astype(np.float32)  # [T,4]\n",
        "\n",
        "class OnTheFlyNowcast(Dataset):\n",
        "    def __init__(self, dsX: xr.Dataset, preds: list, target: str,\n",
        "                 tin: int, lead: int,\n",
        "                 mean_np: np.ndarray, std_np: np.ndarray,\n",
        "                 patch_hw=96, mode=\"train\", samples_per_epoch=1500, seed=42):\n",
        "        self.dsX, self.preds, self.target = dsX, preds, target\n",
        "        self.tin, self.lead = tin, lead\n",
        "        self.mean_np, self.std_np = mean_np, std_np\n",
        "        self.patch_hw, self.mode = patch_hw, mode\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        T = dsX.time.size\n",
        "        self.valid_ends = np.arange(tin-1, T - lead, dtype=int)\n",
        "        self.H = dsX.dims[\"latitude\"]; self.W = dsX.dims[\"longitude\"]\n",
        "        self.N = samples_per_epoch if mode == \"train\" else len(self.valid_ends)\n",
        "\n",
        "    def __len__(self): return self.N\n",
        "\n",
        "    def _pick_end(self, idx):\n",
        "        return int(self.rng.choice(self.valid_ends)) if self.mode==\"train\" else int(self.valid_ends[idx])\n",
        "\n",
        "    def _pick_patch(self):\n",
        "        ph = pw = self.patch_hw\n",
        "        if ph is None or ph >= min(self.H, self.W):\n",
        "            return 0, 0, self.H, self.W\n",
        "        if self.mode == \"train\":\n",
        "            top = self.rng.integers(0, self.H - ph + 1)\n",
        "            left= self.rng.integers(0, self.W - pw + 1)\n",
        "        else:\n",
        "            top = (self.H - ph)//2; left = (self.W - pw)//2\n",
        "        return top, left, ph, pw\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        e = self._pick_end(idx)\n",
        "        t_slice = slice(e-(self.tin-1), e+1)\n",
        "        top, left, ph, pw = self._pick_patch()\n",
        "\n",
        "        # Predictors: (C,T,H,W) as numpy\n",
        "        X_da = self.dsX[self.preds].to_array(\"channel\").isel(\n",
        "            time=t_slice, latitude=slice(top, top+ph), longitude=slice(left, left+pw)\n",
        "        ).transpose(\"channel\",\"time\",\"latitude\",\"longitude\")\n",
        "        X_np = np.asarray(X_da.data, dtype=np.float32)\n",
        "        # Normalize\n",
        "        X_np = (X_np - self.mean_np[:, None, None, None]) / self.std_np[:, None, None, None]\n",
        "\n",
        "        # Time features: [T,4] -> [4,T,1,1] -> broadcast to [4,T,ph,pw]\n",
        "        times = self.dsX.time.isel(time=t_slice).values\n",
        "        tf = make_time_feats(times)                  # [T,4]\n",
        "        TF = np.transpose(tf, (1,0))                # [4,T]\n",
        "        TF = TF[:, :, None, None]                   # [4,T,1,1]\n",
        "        TF = np.broadcast_to(TF, (4, self.tin, ph, pw)).astype(np.float32)  # [4,T,ph,pw]\n",
        "\n",
        "        # Stack features along channel dim: [C+4,T,ph,pw]\n",
        "        X_np = np.concatenate([X_np, TF], axis=0)\n",
        "\n",
        "        # Target at lead (log1p)\n",
        "        y_da = self.dsX[self.target].isel(\n",
        "            time=e+self.lead, latitude=slice(top, top+ph), longitude=slice(left, left+pw)\n",
        "        )\n",
        "        y_np = np.log1p(np.asarray(y_da.data, dtype=np.float32))  # [ph,pw]\n",
        "\n",
        "        return torch.from_numpy(X_np), torch.from_numpy(y_np[None, ...])"
      ],
      "metadata": {
        "id": "2y_pG5dgjHSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_set = OnTheFlyNowcast(\n",
        "    dsX=train_ds, preds=preds_avail, target=\"tp_mmph\",\n",
        "    tin=CFG[\"tin\"], lead=CFG[\"lead_train\"],\n",
        "    mean_np=mean_np, std_np=std_np,\n",
        "    patch_hw=CFG[\"patch_hw\"], mode=\"train\",\n",
        "    samples_per_epoch=CFG[\"samples_per_epoch\"], seed=CFG[\"seed\"]\n",
        ")\n",
        "val_set = OnTheFlyNowcast(\n",
        "    dsX=val_ds, preds=preds_avail, target=\"tp_mmph\",\n",
        "    tin=CFG[\"tin\"], lead=CFG[\"lead_train\"],\n",
        "    mean_np=mean_np, std_np=std_np,\n",
        "    patch_hw=CFG[\"patch_hw\"], mode=\"val\",\n",
        "    samples_per_epoch=min(len(val_ds.time), 300)\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=CFG[\"batch_size\"], shuffle=True,\n",
        "                          num_workers=CFG[\"num_workers\"], pin_memory=False, persistent_workers=False)\n",
        "val_loader   = DataLoader(val_set,   batch_size=CFG[\"batch_size\"], shuffle=False,\n",
        "                          num_workers=CFG[\"num_workers\"], pin_memory=False, persistent_workers=False)"
      ],
      "metadata": {
        "id": "qK8L93w8jJeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DoubleConv3D(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv3d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm3d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm3d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class Down3D(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.pool = nn.MaxPool3d((1,2,2))\n",
        "        self.conv = DoubleConv3D(in_ch, out_ch)\n",
        "    def forward(self, x): return self.conv(self.pool(x))\n",
        "\n",
        "class Up3D(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose3d(in_ch, out_ch, kernel_size=(1,2,2), stride=(1,2,2))\n",
        "        self.conv = DoubleConv3D(in_ch, out_ch)\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size(3) - x1.size(3)\n",
        "        diffX = x2.size(4) - x1.size(4)\n",
        "        x1 = F.pad(x1, [diffX//2, diffX - diffX//2, diffY//2, diffY - diffY//2, 0,0])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNet3DNowcast(nn.Module):\n",
        "    def __init__(self, in_ch, base=16):\n",
        "        super().__init__()\n",
        "        self.inc   = DoubleConv3D(in_ch, base)\n",
        "        self.down1 = Down3D(base, base*2)\n",
        "        self.down2 = Down3D(base*2, base*4)\n",
        "        self.up1   = Up3D(base*4, base*2)\n",
        "        self.up2   = Up3D(base*2, base)\n",
        "        self.out3d = nn.Conv3d(base, base, 3, padding=1)\n",
        "        self.out2d = nn.Conv2d(base, 1, 1)\n",
        "\n",
        "    def forward(self, x):  # [B,C,T,H,W]\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x  = self.up1(x3, x2)\n",
        "        x  = self.up2(x,  x1)\n",
        "        x  = self.out3d(x)       # [B,base,T,H,W]\n",
        "        x  = torch.mean(x, 2)    # temporal pooling\n",
        "        x  = self.out2d(x)       # [B,1,H,W] in log1p space\n",
        "        return x\n",
        "\n",
        "in_ch = len(preds_avail) + 4  # add 4 time features\n",
        "model = UNet3DNowcast(in_ch=in_ch, base=16).to(device)\n",
        "sum(p.numel() for p in model.parameters())/1e6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0mKqy5ojLpH",
        "outputId": "2b889bc7-da5c-429e-a5f8-b79caab22ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.340465"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=CFG[\"lr\"])\n",
        "loss_fn = nn.SmoothL1Loss(beta=0.5)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n",
        "\n",
        "def metrics_mm(y_true_log, y_pred_log):\n",
        "    yt = torch.expm1(y_true_log)\n",
        "    yp = torch.expm1(y_pred_log).clamp(min=0)\n",
        "    mae = torch.mean(torch.abs(yp - yt)).item()\n",
        "    rmse = torch.sqrt(torch.mean((yp - yt)**2)).item()\n",
        "    return mae, rmse\n",
        "\n",
        "best_val = float(\"inf\")\n",
        "for epoch in range(CFG[\"epochs\"]):\n",
        "    model.train()\n",
        "    trL=trMAE=trRMSE=0.0\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    for step, (xb, yb) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{CFG['epochs']} train\", leave=False), 1):\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb) / CFG[\"accum_steps\"]\n",
        "        scaler.scale(loss).backward()\n",
        "        if step % CFG[\"accum_steps\"] == 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "        mae, rmse = metrics_mm(yb, pred)\n",
        "        trL += loss.item()*CFG[\"accum_steps\"]; trMAE += mae; trRMSE += rmse\n",
        "\n",
        "    model.eval()\n",
        "    vaL=vaMAE=vaRMSE=0.0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{CFG['epochs']} val\", leave=False):\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
        "                pred = model(xb)\n",
        "                loss = loss_fn(pred, yb)\n",
        "            mae, rmse = metrics_mm(yb, pred)\n",
        "            vaL += loss.item(); vaMAE += mae; vaRMSE += rmse\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} | train L {trL/len(train_loader):.3f} MAE {trMAE/len(train_loader):.3f} RMSE {trRMSE/len(train_loader):.3f} | \"\n",
        "          f\"val L {vaL/len(val_loader):.3f} MAE {vaMAE/len(val_loader):.3f} RMSE {vaRMSE/len(val_loader):.3f}\")\n",
        "\n",
        "    if (vaRMSE/len(val_loader)) < best_val:\n",
        "        best_val = vaRMSE/len(val_loader)\n",
        "        torch.save(model.state_dict(), os.path.join(OUT_DIR, \"unet3d_best.pth\"))\n",
        "        print(\"  âœ“ Saved best model\")\n",
        "\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "print(\"Training done. Best val RMSE(mm):\", best_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU9I25VSjOBO",
        "outputId": "05c277ad-6413-46c9-c215-facf0ccd1d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train L 0.022 MAE 0.095 RMSE 0.337 | val L 0.009 MAE 0.057 RMSE 0.226\n",
            "  âœ“ Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02 | train L 0.018 MAE 0.083 RMSE 0.309 | val L 0.008 MAE 0.039 RMSE 0.218\n",
            "  âœ“ Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03 | train L 0.016 MAE 0.078 RMSE 0.297 | val L 0.009 MAE 0.042 RMSE 0.225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04 | train L 0.015 MAE 0.075 RMSE 0.286 | val L 0.008 MAE 0.041 RMSE 0.218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05 | train L 0.014 MAE 0.073 RMSE 0.278 | val L 0.008 MAE 0.040 RMSE 0.214\n",
            "  âœ“ Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06 | train L 0.014 MAE 0.071 RMSE 0.268 | val L 0.008 MAE 0.038 RMSE 0.213\n",
            "  âœ“ Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 07 | train L 0.013 MAE 0.068 RMSE 0.258 | val L 0.008 MAE 0.044 RMSE 0.216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 08 | train L 0.012 MAE 0.068 RMSE 0.255 | val L 0.008 MAE 0.051 RMSE 0.220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 09 | train L 0.011 MAE 0.063 RMSE 0.243 | val L 0.008 MAE 0.041 RMSE 0.214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 | train L 0.012 MAE 0.064 RMSE 0.243 | val L 0.008 MAE 0.042 RMSE 0.213\n",
            "Training done. Best val RMSE(mm): 0.2127601852019628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, xarray as xr, pandas as pd, torch, gc\n",
        "from pathlib import Path\n",
        "import rioxarray as rxr\n",
        "\n",
        "# How many rainy cases to export\n",
        "TOP_K = 12\n",
        "\n",
        "def build_input_stack(dsX, preds, mean_np, std_np, t_start, tin):\n",
        "    sel = dsX[preds].isel(time=slice(t_start, t_start+tin)).to_array(\"channel\").transpose(\"channel\",\"time\",\"latitude\",\"longitude\")\n",
        "    X = np.asarray(sel.data, dtype=np.float32)\n",
        "    X = (X - mean_np[:, None, None, None]) / std_np[:, None, None, None]\n",
        "    times = dsX.time.isel(time=slice(t_start, t_start+tin)).values\n",
        "    # Time features â†’ [4, T, H, W]\n",
        "    def make_time_feats(times):\n",
        "        t = pd.to_datetime(times)\n",
        "        hod = t.hour + t.minute/60.0\n",
        "        hod_sin = np.sin(2*np.pi*hod/24.0)\n",
        "        hod_cos = np.cos(2*np.pi*hod/24.0)\n",
        "        doy = t.dayofyear\n",
        "        doy_sin = np.sin(2*np.pi*(doy-1)/365.0)\n",
        "        doy_cos = np.cos(2*np.pi*(doy-1)/365.0)\n",
        "        return np.stack([hod_sin, hod_cos, doy_sin, doy_cos], axis=1).astype(np.float32)\n",
        "    tf = make_time_feats(times)                 # [T,4]\n",
        "    TF = np.transpose(tf, (1,0))               # [4,T]\n",
        "    H = dsX.dims[\"latitude\"]; W = dsX.dims[\"longitude\"]\n",
        "    TF = TF[:, :, None, None]                  # [4,T,1,1]\n",
        "    TF = np.broadcast_to(TF, (4, len(times), H, W)).astype(np.float32)\n",
        "    return np.concatenate([X, TF], axis=0)     # [C+4, T, H, W]\n",
        "\n",
        "def predict_full(model, X_full, patch=192, overlap=32):\n",
        "    device = next(model.parameters()).device\n",
        "    C,T,H,W = X_full.shape\n",
        "    out = np.zeros((H,W), dtype=np.float32)\n",
        "    wgt = np.zeros((H,W), dtype=np.float32)\n",
        "    step = patch - overlap\n",
        "    model.eval()\n",
        "    with torch.no_grad(), torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
        "        for r in range(0, H, step):\n",
        "            for c in range(0, W, step):\n",
        "                rr = min(r+patch, H); cc = min(c+patch, W)\n",
        "                r0 = rr - patch if rr - r < patch else r\n",
        "                c0 = cc - patch if cc - c < patch else c\n",
        "                x = X_full[:, :, r0:rr, c0:cc][None]\n",
        "                y = model(torch.from_numpy(x).to(device)).float().cpu().numpy()[0,0]\n",
        "                y_mm = np.expm1(y).clip(min=0)\n",
        "                out[r0:rr, c0:cc] += y_mm\n",
        "                wgt[r0:rr, c0:cc] += 1.0\n",
        "    out /= np.maximum(wgt, 1e-6)\n",
        "    return out\n",
        "\n",
        "def write_tiff(arr2d, lat, lon, path, varname=\"precip_mm\"):\n",
        "    da = xr.DataArray(arr2d, dims=(\"latitude\",\"longitude\"),\n",
        "                      coords={\"latitude\": lat, \"longitude\": lon}, name=varname)\n",
        "    da = da.rio.write_crs(4326)\n",
        "    da.rio.set_spatial_dims(x_dim=\"longitude\", y_dim=\"latitude\", inplace=True)\n",
        "    da.rio.to_raster(path)\n",
        "\n",
        "# 1) Pick the wettest test times (by 95th percentile across the grid at lead +1)\n",
        "tp = test_ds[\"tp_mmph\"]  # [T,H,W]\n",
        "Tte = tp.sizes[\"time\"]\n",
        "valid_j_start = CFG[\"tin\"]           # need tin hours before for inputs\n",
        "valid_j_end   = Tte - 3              # need +3h available\n",
        "tp_valid = tp.isel(time=slice(valid_j_start, valid_j_end+1))  # times j where +1..+3 exist\n",
        "\n",
        "# Score per time using P95 (more robust than mean)\n",
        "scores = tp_valid.quantile(0.95, dim=(\"latitude\",\"longitude\"), skipna=True).values  # [Ntimes]\n",
        "top_idx_rel = np.argsort(scores)[-TOP_K:][::-1]  # top-K descending\n",
        "cases_e = (valid_j_start + top_idx_rel - 1).tolist()  # window end index e = j-1\n",
        "\n",
        "print(\"Selected rainy window-end indices (e):\", cases_e[:10], \"... total\", len(cases_e))\n",
        "\n",
        "# 2) Run tiled inference for +1h/+2h/+3h on those cases and export GeoTIFFs\n",
        "lat_test = test_ds.latitude.values\n",
        "lon_test = test_ds.longitude.values\n",
        "tif_dir = Path(OUT_DIR) / \"tiffs\"\n",
        "tif_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "times_all = []\n",
        "for ci, e in enumerate(cases_e):\n",
        "    t_start = e - (CFG[\"tin\"] - 1)\n",
        "    Xfull = build_input_stack(test_ds, preds_avail, mean_np, std_np, t_start, CFG[\"tin\"])\n",
        "    preds_leads, truths_leads = [], []\n",
        "    for L in [1,2,3]:\n",
        "        y_pred = predict_full(model, Xfull, patch=CFG.get(\"tile_patch\", 192), overlap=CFG.get(\"tile_overlap\", 32))\n",
        "        preds_leads.append(y_pred)\n",
        "        y_true = np.asarray(test_ds[\"tp_mmph\"].isel(time=e+L).data, dtype=np.float32)\n",
        "        truths_leads.append(y_true)\n",
        "        if L < 3:\n",
        "            # slide window by 1 hour\n",
        "            Xfull = np.concatenate([Xfull[:,1:], Xfull[:, -1:]], axis=1)\n",
        "\n",
        "    for L in [1,2,3]:\n",
        "        write_tiff(preds_leads[L-1], lat_test, lon_test, tif_dir / f\"pred_{ci}_lead{L}.tif\")\n",
        "        write_tiff(truths_leads[L-1], lat_test, lon_test, tif_dir / f\"true_{ci}_lead{L}.tif\")\n",
        "\n",
        "    times = pd.to_datetime(test_ds.time.values)\n",
        "    times_all.append(np.array([times[e+1], times[e+2], times[e+3]], dtype=\"datetime64[s]\"))\n",
        "\n",
        "np.savez(os.path.join(OUT_DIR, \"sample_preds.npz\"),\n",
        "         preds=np.array([0]), truths=np.array([0]),\n",
        "         times=np.array(times_all), lat=lat_test, lon=lon_test)\n",
        "\n",
        "print(f\"Exported {len(cases_e)} rainy cases to\", tif_dir)\n",
        "gc.collect(); torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu--iUkRx9s1",
        "outputId": "1a0dbac9-1aab-454c-c5f9-aed7cef42e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected rainy window-end indices (e): [81, 46, 80, 79, 47, 78, 45, 44, 72, 82] ... total 12\n",
            "Exported 12 rainy cases to /content/neural_weather_outputs/tiffs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rioxarray as rxr\n",
        "\n",
        "def build_input_stack(dsX, preds, mean_np, std_np, t_start, tin):\n",
        "    sel = dsX[preds].isel(time=slice(t_start, t_start+tin)).to_array(\"channel\").transpose(\"channel\",\"time\",\"latitude\",\"longitude\")\n",
        "    X = np.asarray(sel.data, dtype=np.float32)\n",
        "    X = (X - mean_np[:, None, None, None]) / std_np[:, None, None, None]\n",
        "\n",
        "    # Time features â†’ [4,T,H,W]\n",
        "    times = dsX.time.isel(time=slice(t_start, t_start+tin)).values\n",
        "    tf = make_time_feats(times)                 # [T,4]\n",
        "    TF = np.transpose(tf, (1,0))               # [4,T]\n",
        "    H = dsX.dims[\"latitude\"]; W = dsX.dims[\"longitude\"]\n",
        "    TF = TF[:, :, None, None]                  # [4,T,1,1]\n",
        "    TF = np.broadcast_to(TF, (4, tin, H, W)).astype(np.float32)\n",
        "\n",
        "    return np.concatenate([X, TF], axis=0)     # [C+4, T, H, W]\n",
        "\n",
        "def predict_full(model, X_full, patch=192, overlap=32):\n",
        "    C,T,H,W = X_full.shape\n",
        "    out = np.zeros((H,W), dtype=np.float32)\n",
        "    wgt = np.zeros((H,W), dtype=np.float32)\n",
        "    step = patch - overlap\n",
        "    model.eval()\n",
        "    with torch.no_grad(), torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
        "        for r in range(0, H, step):\n",
        "            for c in range(0, W, step):\n",
        "                rr = min(r+patch, H); cc = min(c+patch, W)\n",
        "                r0 = rr - patch if rr - r < patch else r\n",
        "                c0 = cc - patch if cc - c < patch else c\n",
        "                x = X_full[:, :, r0:rr, c0:cc][None]\n",
        "                y = model(torch.from_numpy(x).to(device)).float().cpu().numpy()[0,0]\n",
        "                y_mm = np.expm1(y).clip(min=0)\n",
        "                out[r0:rr, c0:cc] += y_mm\n",
        "                wgt[r0:rr, c0:cc] += 1.0\n",
        "    out /= np.maximum(wgt, 1e-6)\n",
        "    return out\n",
        "\n",
        "def write_tiff(arr2d, lat, lon, path, varname=\"precip_mm\"):\n",
        "    da = xr.DataArray(arr2d, dims=(\"latitude\",\"longitude\"),\n",
        "                      coords={\"latitude\": lat, \"longitude\": lon}, name=varname)\n",
        "    da = da.rio.write_crs(4326)\n",
        "    da.rio.set_spatial_dims(x_dim=\"longitude\", y_dim=\"latitude\", inplace=True)\n",
        "    da.rio.to_raster(path)\n",
        "\n",
        "lat_test = test_ds.latitude.values\n",
        "lon_test = test_ds.longitude.values\n",
        "tif_dir = Path(OUT_DIR) / \"tiffs\"\n",
        "tif_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "Tte = test_ds.time.size\n",
        "cases_e = [CFG[\"tin\"]-1 + k*6 for k in range(5) if (CFG[\"tin\"]-1 + k*6 + 3) < Tte]\n",
        "print(\"Window end indices:\", cases_e)\n",
        "\n",
        "times_all = []\n",
        "for ci, e in enumerate(cases_e):\n",
        "    t_start = e - (CFG[\"tin\"] - 1)\n",
        "    Xfull = build_input_stack(test_ds, preds_avail, mean_np, std_np, t_start, CFG[\"tin\"])\n",
        "    preds_leads, truths_leads = [], []\n",
        "    for L in [1,2,3]:\n",
        "        y_pred = predict_full(model, Xfull, patch=CFG[\"tile_patch\"], overlap=CFG[\"tile_overlap\"])\n",
        "        preds_leads.append(y_pred)\n",
        "        y_true = np.asarray(test_ds[\"tp_mmph\"].isel(time=e+L).data, dtype=np.float32)\n",
        "        truths_leads.append(y_true)\n",
        "        if L < 3:\n",
        "            Xfull = np.concatenate([Xfull[:,1:], Xfull[:, -1:]], axis=1)  # slide 1h\n",
        "    for L in [1,2,3]:\n",
        "        write_tiff(preds_leads[L-1], lat_test, lon_test, tif_dir / f\"pred_{ci}_lead{L}.tif\")\n",
        "        write_tiff(truths_leads[L-1], lat_test, lon_test, tif_dir / f\"true_{ci}_lead{L}.tif\")\n",
        "    times = pd.to_datetime(test_ds.time.values)\n",
        "    times_all.append(np.array([times[e+1], times[e+2], times[e+3]], dtype=\"datetime64[s]\"))\n",
        "\n",
        "np.savez(os.path.join(OUT_DIR, \"sample_preds.npz\"),\n",
        "         preds=np.array([0]), truths=np.array([0]),\n",
        "         times=np.array(times_all), lat=lat_test, lon=lon_test)\n",
        "\n",
        "print(\"Saved GeoTIFFs and sample_preds.npz to\", tif_dir)"
      ],
      "metadata": {
        "id": "IPQp6S5xjQpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a213b5-ee06-4a29-e325-086a4eaa5e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Window end indices: [5, 11, 17, 23, 29]\n",
            "Saved GeoTIFFs and sample_preds.npz to /content/neural_weather_outputs/tiffs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from pathlib import Path\n",
        "import leafmap.foliumap as leafmap\n",
        "\n",
        "st.set_page_config(page_title=\"Neural Weather Forecaster\", layout=\"wide\")\n",
        "st.title(\"Neural Weather Pattern Forecaster ðŸŒ¦ï¸\")\n",
        "st.caption(\"ERA5 India (Apr 2025) â€” 3D U-Net nowcasting (+1h/+2h/+3h). Rainfall is sparse by nature, use the scale slider to enhance visibility.\")\n",
        "\n",
        "OUT_DIR = Path(\"/content/neural_weather_outputs\")\n",
        "ASSETS = OUT_DIR / \"tiffs\"\n",
        "NPZ = OUT_DIR / \"sample_preds.npz\"\n",
        "\n",
        "if not ASSETS.exists():\n",
        "    st.error(\"Assets folder missing. Run the export step.\")\n",
        "    st.stop()\n",
        "\n",
        "cases = sorted(set(p.stem.split(\"_\")[1] for p in ASSETS.glob(\"pred_*_lead*.tif\")))\n",
        "leads = [1, 2, 3]\n",
        "\n",
        "# UI\n",
        "col0, col1, col2 = st.columns([1,1,2])\n",
        "with col0: case = st.selectbox(\"Case\", options=cases, index=0)\n",
        "with col1: lead = st.selectbox(\"Lead (+hours)\", options=leads, index=0)\n",
        "\n",
        "# Determine sensible vmax from truth raster stats\n",
        "true_path = ASSETS / f\"true_{case}_lead{lead}.tif\"\n",
        "pred_path = ASSETS / f\"pred_{case}_lead{lead}.tif\"\n",
        "with rasterio.open(true_path) as src:\n",
        "    arr = src.read(1).astype(np.float32)\n",
        "    arr[arr <= 0] = np.nan\n",
        "    p95 = float(np.nanpercentile(arr, 95)) if np.isfinite(np.nanpercentile(arr, 95)) else 10.0\n",
        "with rasterio.open(pred_path) as src:\n",
        "    arrp = src.read(1).astype(np.float32)\n",
        "    arrp[arrp <= 0] = np.nan\n",
        "    p95p = float(np.nanpercentile(arrp, 95)) if np.isfinite(np.nanpercentile(arrp, 95)) else 10.0\n",
        "\n",
        "default_vmax = max(5.0, round(max(p95, p95p), 1))\n",
        "with col2:\n",
        "    vmax = st.slider(\"Max scale (mm/h)\", min_value=1.0, max_value=100.0, value=min(default_vmax, 30.0), step=1.0)\n",
        "vmin = 0.0\n",
        "\n",
        "def center_from_tiff(path):\n",
        "    with rasterio.open(path) as src:\n",
        "        b = src.bounds\n",
        "    return [(b.top + b.bottom) / 2, (b.left + b.right) / 2]\n",
        "\n",
        "m = leafmap.Map(center=center_from_tiff(true_path), zoom=5, draw_control=False, measure_control=False, fullscreen_control=True)\n",
        "\n",
        "# Try localtileserver path; else fallback to ImageOverlay\n",
        "try:\n",
        "    import localtileserver  # noqa: F401\n",
        "    HAS_LTS = True\n",
        "except Exception:\n",
        "    HAS_LTS = False\n",
        "\n",
        "if HAS_LTS:\n",
        "    # Add truth beneath, prediction on top\n",
        "    m.add_raster(str(true_path), layer_name=\"Truth (mm/h)\", colormap=\"Blues\", vmin=vmin, vmax=vmax, opacity=0.85)\n",
        "    m.add_raster(str(pred_path), layer_name=\"Prediction (mm/h)\", colormap=\"Oranges\", vmin=vmin, vmax=vmax, opacity=0.60)\n",
        "else:\n",
        "    # Lightweight fallback using ImageOverlay with manual scaling\n",
        "    import folium\n",
        "    from PIL import Image\n",
        "    import matplotlib.cm as cm\n",
        "\n",
        "    def overlay_raster(map_obj, tif_path, layer_name, cmap_name, vmin=0.0, vmax=10.0, opacity=0.8):\n",
        "        with rasterio.open(tif_path) as src:\n",
        "            arr = src.read(1).astype(np.float32)\n",
        "            bounds = [[src.bounds.bottom, src.bounds.left], [src.bounds.top, src.bounds.right]]\n",
        "            nodata = src.nodata\n",
        "            mask = ~np.isfinite(arr) | ((arr == nodata) if nodata is not None else False) | (arr <= vmin)\n",
        "            norm = np.clip((arr - vmin) / (vmax - vmin + 1e-6), 0, 1)\n",
        "            rgba = (cm.get_cmap(cmap_name)(norm) * 255).astype(np.uint8)\n",
        "            rgba[mask, 3] = 0\n",
        "            img = Image.fromarray(rgba, mode=\"RGBA\")\n",
        "        folium.raster_layers.ImageOverlay(image=img, bounds=bounds, name=layer_name, opacity=opacity, interactive=True).add_to(map_obj)\n",
        "\n",
        "    overlay_raster(m, str(true_path), \"Truth (mm/h)\", \"Blues\", vmin=vmin, vmax=vmax, opacity=0.85)\n",
        "    overlay_raster(m, str(pred_path), \"Prediction (mm/h)\", \"Oranges\", vmin=vmin, vmax=vmax, opacity=0.60)\n",
        "\n",
        "m.add_layer_control()\n",
        "st.subheader(\"Interactive map\")\n",
        "m.to_streamlit(height=650)\n",
        "\n",
        "# Timestamp if saved\n",
        "if NPZ.exists():\n",
        "    dat = np.load(NPZ, allow_pickle=True)\n",
        "    times = dat[\"times\"]\n",
        "    try:\n",
        "        trow = int(case)\n",
        "        tval = times[trow][lead - 1]\n",
        "        st.caption(f\"Valid time: {np.datetime_as_string(tval, unit='s')}\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.write(\"Tip: Increase 'Max scale (mm/h)' to highlight heavier rain. Try different cases; we picked the wettest hours to ensure visible patterns.\")"
      ],
      "metadata": {
        "id": "lSqOFWlJjXCV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e3f5301-bc15-4c89-8330-9bf45a2f78d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop any previous app\n",
        "!pkill -f \"streamlit run app.py\" || true\n",
        "\n",
        "# Launch Streamlit with ngrok\n",
        "import subprocess, os\n",
        "from pyngrok import ngrok\n",
        "from getpass import getpass\n",
        "\n",
        "port = 8501\n",
        "proc = subprocess.Popen(\n",
        "    [\"streamlit\", \"run\", \"app.py\", \"--server.port\", str(port), \"--server.address\", \"0.0.0.0\"],\n",
        "    stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True\n",
        ")\n",
        "NGROK_AUTH_TOKEN = os.environ.get(\"NGROK_AUTH_TOKEN\") or getpass(\"Paste your ngrok auth token: \")\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "public_url = ngrok.connect(port, \"http\")\n",
        "print(\"Your Streamlit app is live at:\", public_url)"
      ],
      "metadata": {
        "id": "qg3ndLGejZF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e439f60-5efa-4ec7-a5e8-ea77216076e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "Paste your ngrok auth token: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Your Streamlit app is live at: NgrokTunnel: \"https://chololithic-myrtle-fernless.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UWyAN11qsVTF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}